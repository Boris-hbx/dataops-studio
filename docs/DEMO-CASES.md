# DataOps Studio 演示方案

**日期**: 2026-02-01
**版本**: v1.0

---

## 一、演示总原则

1. **领导亲自操作** — 关键环节让领导输入指令、点击按钮
2. **先展后练** — 先用 2-3 分钟展示平台现有能力，再进入互动环节
3. **量身定制** — 每类领导看到的重点不同，但都包含 AI 协作环节
4. **闭环交付** — 每个 demo 都有可见产出（代码、Spec、提交记录）

---

## 二、受众分析

| 类型 |  核心关注点 | 关键词 |
|------|-----------|--------|
| 研究院主管 |  创新、竞争力、大模型、对基模的帮助、数据价值 | AI 创新、代码知识挖掘、模型训练数据、灵犀 |
| 平台管理主管 | 平台能力、增量迭代、openclaw | 渐进演进、可管可控、平台复用 |
| 研发交付主管 |  研发效率、质量、可信 | 效能提升、质量内建、工程经验沉淀、可信要求 |

---

## 三、演示 Case

### Case A: 研究院主管（芊总、勇总、蔡总）

**演示主题**: "AI Agent 如何自主完成从需求到交付的全流程 + 代码知识挖掘"

**背景说明**: 芊总是大模型重度使用者，车 BU 也有很多实践，关注对基模的帮助，尤其数据层面，是否可以帮助数据组。

#### 场景 A1: 代码知识挖掘工具（推荐给芊总）

**需求描述**: 给定某个代码仓，挖掘其中有助于代码模型训练的可学习知识；或者开发可用于此场景的工具。

| 步骤 | 操作者 | 内容 | 展示要点 |
|------|--------|------|---------|
| 1 | 演示者 | 打开 DataOps Studio 前端，浏览 Dashboard → Data Lineage | 平台已有的数据管理能力 |
| 2 | 演示者 | 打开 Agent 标注模块，导入示例会话 JSON，展示标注工作台 | 标注数据如何反哺模型训练（RLHF 闭环）|
| 3 | 演示者 | 打开终端，展示 `.claude/agents/` 目录下 Agent 定义文件，讲解"AI 团队"架构 | 多 Agent 协作体系：PO、架构师、UX、Challenger、开发者、测试、审查员 |
| 4 | **芊总** | 在终端输入：`/team-fullstack 开发一个"代码知识挖掘"工具模块，能够分析指定代码仓库，自动提取函数签名、调用关系、设计模式等结构化知识，输出为可用于代码大模型训练的 JSONL 数据集` | 观看 AI 团队自主协作全过程 |
| 5 | 观察 | AI 团队执行：PO 分析意图 → 架构师设计方案 → Challenger 挑战风险 → 任务拆解 → 施工 → 验收 | 9 个 Stage 自主流转，每阶段产出可见 |
| 6 | 演示者 | 展示产出：Spec 文件、新增代码、Git commit 记录 | 完整工程交付物 |

**原理介绍环节**（打开文件讲解）:
- `.claude/agents/` — Agent 定义文件，展示多角色分工
- `.claude/commands/team-fullstack.md` — 团队编排流程
- `docs/spec/SPEC-004-agent-tool-annotation.md` — Spec 示例，展示结构化产出
- `backend/agent_annotation.py` — 标注模块代码，展示 AI 交付的代码质量

**话术重点**:
- "这不是 ChatGPT 聊天，而是一个有角色分工、有流程管控的 AI 开发团队"
- "标注模块产出的数据可以直接用于模型训练，形成 数据→标注→训练→Agent→标注 的闭环"
- "代码知识挖掘工具可以帮助数据组从现有代码仓中提取高质量训练数据"
- "Challenger 角色会主动挑战方案风险，不是无脑执行"

#### 场景 A2: 对灵犀有帮助的场景（推荐给勇总）

| 步骤 | 操作者 | 内容 | 展示要点 |
|------|--------|------|---------|
| 1 | 演示者 | 展示 DataOps Studio 的 Agent 标注模块 + RLHF 标注模块 | 标注体系支持 5 种 RLHF 类型 + Agent 工具调用标注 |
| 2 | 演示者 | 展示多格式导入能力（OpenAI/Anthropic/自定义格式自动检测） | 兼容灵犀的数据格式 |
| 3 | **勇总** | 在终端输入：`/team-fullstack 增加一个"对话质量自动评估"模块，能够对 AI 对话日志进行多维度自动打分（流畅度、相关性、准确性、安全性），并生成质量报告，支持批量评估` | 对灵犀对话质量管控有直接帮助 |
| 4 | 观察 | AI 团队执行全流程 | 关注 Spec 中对评估维度的定义、数据模型设计 |

**话术重点**:
- "这套标注和评估能力可以直接应用到灵犀的对话质量管控中"
- "多格式自动检测导入，不需要手动转换数据格式"

---

### Case B: 平台管理主管（童老、刘金虎）

**演示主题**: "AI 辅助的平台渐进式迭代——从需求到上线的可控流程"

**背景说明**: 平台类领导，关注基于已有应用的增量迭代，openclaw 场景。

#### 场景 B1: 平台增量迭代（标准演示）

| 步骤 | 操作者 | 内容 | 展示要点 |
|------|--------|------|---------|
| 1 | 演示者 | 打开 DataOps Studio 前端全貌，逐页浏览：Dashboard → Pipelines → Data Quality → Cost Analysis → Data Lineage | 平台已具备的 5 大核心能力 |
| 2 | 演示者 | 打开 `CLAUDE.md`，展示项目技术栈定义（唯一真相源）、工程规范体系 | 技术栈统一管控，不是"各写各的" |
| 3 | 演示者 | 打开 `docs/spec/` 目录，展示已有 Spec 文件 | 每个功能都有结构化需求文档，可追溯 |
| 4 | **领导** | 在终端输入：`/team-baoxing 在 Dashboard 页面增加一个"平台健康度评分"卡片，综合管道成功率、数据质量分和成本趋势给出 0-100 的综合评分` | 一个典型的渐进式迭代需求 |
| 5 | 观察 | AI 执行：PO 分析 → 架构+UX 设计 → 风险质疑 → 施工 → 验收 → 交付 | 重点关注：Spec 落盘、风险质疑、验收环节 |
| 6 | 演示者 | 刷新浏览器，展示 Dashboard 上新增的卡片 | 需求到可见产出的闭环 |
| 7 | 演示者 | 展示 Git log 和 Spec 文件变更 | 过程可审计、可追溯 |

**原理介绍环节**（打开文件讲解）:
- `CLAUDE.md` — 项目技术栈唯一真相源，AI 严格遵守
- `.claude/commands/team-baoxing.md` — 团队编排定义，展示流程可配置
- `docs/spec/` — Spec 文件目录，展示历史迭代档案
- `.claude/standards/` — 工程规范（MUST/SHOULD/MAY 三级）

**话术重点**:
- "每个迭代都有 Spec 文档、风险评估、验收检查，不是黑盒"
- "技术栈在 CLAUDE.md 统一定义，AI 团队严格遵守，不会引入未经批准的依赖"
- "Spec 每个阶段都落盘保存，即使 AI 中断也能恢复继续"
- "这套流程可以融入现有的研发管理体系，AI 是加速器不是替代者"
- "同样的模式可以应用到 openclaw 等平台的增量迭代中"

#### 场景 B2: 备选 — 快速功能扩展

如果时间有限，可用更简单的需求：

> `/team-baoxing 在侧边栏增加一个"系统设置"页面，包含主题切换（亮色/暗色）和语言切换（中/英）`

优点：需求简单明确，执行快，产出直观可见。

---

### Case C: 研发交付主管（吴局、汪浩、鲁总、贾总）

**演示主题**: "AI 驱动的研发效能提升——质量内建、规范先行、经验可沉淀"

**背景说明**: 研发类领导，关注研发效率、质量、工程经验沉淀、可信要求。

#### 场景 C1: 特性开发 + 质量内建（标准演示）

| 步骤 | 操作者 | 内容 | 展示要点 |
|------|--------|------|---------|
| 1 | 演示者 | 展示工程规范体系：`.claude/standards/` 目录 | 规范不是口号，是 AI 执行的硬约束（MUST/SHOULD/MAY）|
| 2 | 演示者 | 展示 Agent 团队架构图（team-fullstack 流程图），讲解 9 个 Stage 的质量关卡 | Stage 3 风险质疑 + Stage 7 四方验收 |
| 3 | 演示者 | 打开 `agent-test.md`、`agent-reviewer.md`、`agent-security.md`，展示质量保障角色的检查清单 | 质量不是"事后补"，而是内建在流程中 |
| 4 | 演示者 | 展示 SPEC-004（已完成的 Spec），逐节讲解：Why → DoD → 技术方案 → 风险清单 → 决策记录 | 每个功能交付的完整档案 |
| 5 | **领导** | 在终端输入：`/team-fullstack 给数据质量模块增加"质量规则自动推荐"功能，基于历史检查结果自动推荐新的质量规则，并说明推荐理由` | 有复杂度的需求，充分展示多阶段协作 |
| 6 | 观察 | 重点关注：Challenger 质疑环节、验收环节（lint/test + 代码审查 + 安全检查） | AI 不是"什么都说好"，Challenger 会主动找问题 |
| 7 | 演示者 | 执行 lint + test 命令，展示通过结果 | ruff check + eslint + pytest + vitest |
| 8 | 演示者 | 展示 Git commit 记录（Conventional Commits 格式）和 Spec 文件 | 交付物规范、可追溯 |

**原理介绍环节**（打开文件讲解）:
- `.claude/agents/agent-challenger.md` — Challenger 角色定义，展示如何"挑刺"
- `.claude/agents/agent-test.md` — 测试工程师角色，展示质量检查清单
- `.claude/agents/agent-reviewer.md` — 审查员角色，展示代码规范检查项
- `.claude/agents/agent-security.md` — 安全审计角色，展示安全检查维度
- `CLAUDE.md` → Toolchain Commands — 统一的验证命令
- `docs/spec/SPEC-004-agent-tool-annotation.md` — 完整 Spec 示例

**话术重点**:
- "AI 团队内建了 Challenger 角色，每个方案都要经过质疑，P0 风险不解决不施工"
- "验收是四方联合：测试工程师跑 lint+test、审查员检查代码规范、UX 验交互、安全审 API"
- "所有代码经过 ruff（Python）和 ESLint（JS）静态检查，格式化由 Prettier 和 ruff format 保证"
- "这套体系的核心价值不是'AI 写代码快'，而是'AI 按规范写代码、按流程交付'"
- "工程经验沉淀在 standards/ 和 agents/ 中，团队成员变动不影响质量标准"
- "满足可信要求：过程可审计（Spec + Git）、质量可验证（lint + test）、风险可追溯（风险清单 + 决策记录）"

#### 场景 C2: 工程经验沉淀（加分项）

如果有额外时间，可以展示"如何将团队经验沉淀为 AI 可执行的规范"：

| 步骤 | 操作者 | 内容 |
|------|--------|------|
| 1 | 演示者 | 打开一个 standards 文件，讲解 MUST/SHOULD/MAY 三级规范格式 |
| 2 | **领导** | 口述一条团队规范，例如"所有 API 必须有入参校验" |
| 3 | 演示者 | 将其写入 standards 文件，展示 AI 后续开发时自动遵守 |

**话术**: "团队的工程经验不再只存在于人的脑子里，而是沉淀为 AI 可执行的规范"

---

## 四、推荐优先级

| 优先级 | 领导 | 推荐 Case | 理由 |
|--------|------|-----------|------|
| P0 | 芊总 | Case A1（代码知识挖掘） | 大模型重度使用者，直接关注数据和模型训练，代码知识挖掘与其关注点高度契合 |
| P0 | 研发交付主管 | Case C1（特性开发+质量内建） | 最能体现工程价值，质量/规范/效能/可信是核心关注点 |
| P1 | 勇总 | Case A2（对话质量评估） | 与灵犀直接相关 |
| P1 | 平台管理主管 | Case B1（平台增量迭代） | 渐进迭代场景直观，展示可控流程 |
| P2 | 蔡总 | Case A1 或 A2 | 根据现场兴趣选择 |

---

## 五、演示环境准备清单

### 环境启动

```bash
# 1. 启动后端
cd backend && python -m uvicorn main:app --reload --port 8000

# 2. 启动前端
cd frontend && npx vite --port 6660

# 3. 浏览器打开
http://localhost:6660
```

### 演示前检查

- [ ] 后端正常运行（访问 http://localhost:8000/docs 可见 API 文档）
- [ ] 前端正常运行（访问 http://localhost:6660 可见 Dashboard）
- [ ] Git 状态干净（`git status` 无未提交变更）
- [ ] 示例数据就位（`backend/data/agent-samples/` 下有 3 个 JSON 文件）
- [ ] 提前测试一次 `/team-fullstack` 或 `/team-baoxing`，确认端到端流程正常
- [ ] Claude Code 终端准备好，字体大小适合投屏

### 需要准备的文件/PPT

| 内容 | 文件路径 | 用途 |
|------|---------|------|
| Agent 团队架构 | `.claude/agents/` 目录 | 讲解多角色分工 |
| 团队编排流程 | `.claude/commands/team-fullstack.md` | 讲解 9 Stage 流程图 |
| 工程规范 | `.claude/standards/` 目录 | 讲解 MUST/SHOULD/MAY |
| 项目配置 | `CLAUDE.md` | 讲解技术栈唯一真相源 |
| Spec 示例 | `docs/spec/SPEC-004-agent-tool-annotation.md` | 讲解结构化产出 |
| API 文档 | `http://localhost:8000/docs` | 展示自动生成的 API 文档 |

### 备选演示需求（领导临场自选）

| 难度 | 需求描述 | 适合场景 |
|------|---------|---------|
| 简单 | "在侧边栏增加一个系统设置页面" | 时间紧，快速展示 |
| 中等 | "给 Dashboard 增加平台健康度仪表盘" | 平台管理主管 |
| 中等 | "增加一个对话质量自动评估模块" | 研究院主管 |
| 中等 | "增加质量规则自动推荐功能" | 研发交付主管 |
| 复杂 | "开发代码知识挖掘工具模块" | 研究院主管（芊总） |

---

## 六、演示话术要点总结

### 通用话术

- "这是一个多 Agent 协作的 AI 开发团队，不是简单的代码生成工具"
- "每个功能都经过：需求分析 → 方案设计 → 风险质疑 → 实现 → 验收，全程可追溯"
- "AI 严格遵守项目定义的技术栈和工程规范，不会随意引入新依赖"

### 差异化话术

| 受众 | 核心话术 |
|------|---------|
| 研究院主管 | "标注闭环：数据→标注→训练→Agent→标注"，"代码知识挖掘为基模训练提供高质量数据" |
| 平台管理主管 | "渐进迭代可控"，"Spec 落盘可恢复"，"技术栈统一管控" |
| 研发交付主管 | "质量内建不是事后补"，"经验沉淀为 AI 可执行规范"，"满足可信要求：可审计、可验证、可追溯" |
